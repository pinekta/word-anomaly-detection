{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e10334-3ead-44a1-a920-d6ca7fa66a5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 松原2021/12 20%ルール TensorFlowによる文字列項目の異常検知\n",
    "\n",
    "## 1. 使い方\n",
    "\n",
    "id, 文字列形式のCSVを用意し\n",
    "用意したらファイル名を\n",
    "*namedata.csv* にして\n",
    "本jupyter notebookのあるディレクトリにアップロードしてください。\n",
    "\n",
    "次にそれぞれのブロックを▶︎ボタンを押して実行していきます。\n",
    "「5. 文字列を入力して異常か検証」でテキストボックスが表示されるので、\n",
    "そこで検証したい文字列を入力したあと、▶︎ボタンを押してブロックを実行してください。\n",
    "入力文字列が異常値かどうかが判定されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e3903-f476-4a3a-a26f-637ba76e1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "from scipy.stats import chi2\n",
    "import csv\n",
    "\n",
    "def fetch_name_from_csv(path):\n",
    "    \"\"\"\n",
    "    csvを読み込み名前を取ってくる\n",
    "    \"\"\"\n",
    "    csv_file = open(path, \"r\", encoding=\"utf-8\", errors=\"\", newline=\"\")\n",
    "    f = csv.reader(csv_file, delimiter=\",\", doublequote=True, lineterminator=\"\\n\", quotechar='\"', skipinitialspace=True)\n",
    "    header = next(f)\n",
    "    \n",
    "    names = []\n",
    "    for row in f:\n",
    "        names.append(row[1])\n",
    "\n",
    "    return names    \n",
    "\n",
    "names = fetch_name_from_csv(\"./namedata.csv\")\n",
    "\n",
    "# print(len(names))\n",
    "# print(names[1])\n",
    "\n",
    "print(\"処理が完了したので次の処理を実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521175d2-c651-4164-8c84-b6fd48889379",
   "metadata": {},
   "source": [
    "## 2. データセット作成\n",
    "\n",
    "データセットはモデル開発用(dev)とテスト用(test)の2つ用意します。8割を開発用に、残り2割をテスト用に使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab30de-5746-450b-aa34-296e7e1b0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正しい名前にラベル0、正しくない名前にラベル1を付与\n",
    "name_length = len(names)\n",
    "name_arr = np.hstack([np.reshape(np.zeros(name_length), (-1, 1)), np.reshape(names, (-1, 1))])\n",
    "# chabsa_length = len(chabsa_texts)\n",
    "# chabsa_arr = np.hstack([np.reshape(np.ones(chabsa_length), (-1, 1)), np.reshape(chabsa_texts, (-1, 1))])\n",
    "\n",
    "\n",
    "# 各データの数を決定\n",
    "num_s_dev = int(name_length * 0.8)\n",
    "num_c_dev = int(num_s_dev * 0.01)\n",
    "num_s_test = name_length - num_s_dev\n",
    "num_c_test = num_s_test\n",
    "\n",
    "# print(\"開発データ　 正しいやつ:{}, 正しくないやつ:{}\".format(num_s_dev, num_c_dev))\n",
    "# print(\"テストデータ 正しいやつ:{}, 正しくないやつ:{}\".format(num_s_test, num_c_test))\n",
    "\n",
    "# data split\n",
    "s_dev, s_test = train_test_split(name_arr, train_size=num_s_dev)\n",
    "# c_dev, c_test = train_test_split(chabsa_arr, train_size=num_c_dev)\n",
    "# c_test, _ = train_test_split(c_test, train_size=num_c_test)\n",
    "\n",
    "# シャッフル\n",
    "# dev_arr = np.vstack([s_dev, c_dev])\n",
    "dev_arr = np.vstack([s_dev])\n",
    "np.random.shuffle(dev_arr)\n",
    "# test_arr = np.vstack([s_test, c_test])\n",
    "test_arr = np.vstack([s_test])\n",
    "np.random.shuffle(test_arr)\n",
    "\n",
    "# print(dev_arr.shape, test_arr.shape)\n",
    "\n",
    "print(\"処理が完了したので次の処理を実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a1765-c8f3-498c-8122-6bb81bfe5d3c",
   "metadata": {},
   "source": [
    "## 3. 異常検知モデル開発\n",
    "\n",
    "Universal Sentence Encoder (USE) Multilingual, CNN版を使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c283a1-0c1e-4aaa-91f3-34260298d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"処理実行中です。画像が出力されるまでしばらくお待ちください。\")\n",
    "\n",
    "# モデルをtfhubからインポート\n",
    "use_url = 'https://tfhub.dev/google/universal-sentence-encoder-multilingual/3'\n",
    "embed = hub.load(use_url)\n",
    "\n",
    "def get_embeddings(texts, batch_size=100):\n",
    "    \"\"\"\n",
    "    文字列のリストを埋め込みベクトルのリスト(np.ndarray)に変換\n",
    "    \"\"\"\n",
    "    length = len(texts)\n",
    "    n_loop = int(length / batch_size) + 1\n",
    "    embeddings = embed(texts[: batch_size])\n",
    "    for i in range(1, n_loop):\n",
    "        arr = embed(texts[batch_size*i: min(batch_size*(i+1), length)])\n",
    "        embeddings = tf.concat([embeddings, arr], axis=0)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "dev_embeddings = get_embeddings(dev_arr[:, 1])\n",
    "test_embeddings = get_embeddings(test_arr[:, 1])\n",
    "# print(dev_embeddings.shape, test_embeddings.shape)\n",
    "\n",
    "\n",
    "# 平均方向の推定値$\\hat{\\mu}$を求める\n",
    "mu = np.mean(dev_embeddings, axis=0)\n",
    "mu /= np.linalg.norm(mu)\n",
    "# print(mu.shape)\n",
    "\n",
    "\n",
    "# 異常度を計算し、異常度の従うカイ2乗分布のパラメータ$\\hat{m}$と$\\hat{s}$を推定\n",
    "anom = 1 - np.inner(mu, dev_embeddings)\n",
    "anom_mean = np.mean(anom)\n",
    "anom_mse = np.mean(anom**2) - anom_mean**2\n",
    "mhat = 2 * anom_mean**2 / anom_mse\n",
    "shat = 0.5 * anom_mse / anom_mean\n",
    "# print(\"mhat: {:.1f}\".format(mhat))\n",
    "# print(\"shat: {:.3e}\".format(shat))\n",
    "\n",
    "\n",
    "# カイ2乗分布の確率密度関数PDFと累積分布関数CDFをプロット\n",
    "x = np.linspace(0, 1, 100)\n",
    "plt.plot(x, chi2.pdf(x, mhat, loc=0, scale=shat), c='r')\n",
    "plt.title(\"PDF\", fontsize=18)\n",
    "plt.xlabel(\"a\", fontsize=18)\n",
    "plt.hist(anom, bins=100, density=True, range=(0,1), color=(0,1,0,0.5))\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.xlim(0,1)\n",
    "plt.grid()\n",
    "plt.savefig(\"./PDF.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "plt.plot(x, chi2.cdf(x, mhat, loc=0, scale=shat), c='b')\n",
    "plt.title(\"CDF\", fontsize=18)\n",
    "plt.xlabel(\"a\", fontsize=18)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.xlim(0,1)\n",
    "plt.grid()\n",
    "plt.savefig(\"./CDF.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def iteration_solver(alpha, mhat, shat, x_ini=0.8, eps=1.e-12, n_ite=100):\n",
    "    \"\"\"\n",
    "    Solve equation\n",
    "    $$1-\\alpha = \\int_0^x \\\\! dx\\, \\chi^2 (x|\\hat{m}, \\hat{s}) $$\n",
    "    for x by Newtonian method.\n",
    "    \"\"\"\n",
    "    x = x_ini\n",
    "    for i in range(n_ite):\n",
    "        xnew = x - (chi2.cdf(x, mhat, loc=0, scale=shat) - (1 - alpha)) / chi2.pdf(x, mhat, loc=0, scale=shat)\n",
    "        if abs(xnew - x) < eps:\n",
    "            print(\"iteration: \", i+1)\n",
    "            break\n",
    "        x = xnew\n",
    "    return xnew\n",
    "\n",
    "alpha = 0.01\n",
    "ath = iteration_solver(alpha, mhat, shat)\n",
    "print(\"ath: {:.4f}\".format(ath))\n",
    "\n",
    "print(\"次の処理を実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aeeca4-93f9-467f-86ff-4cdd99d9c585",
   "metadata": {},
   "source": [
    "## 4. 精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6975c-1950-4829-b5ae-53bff69a4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"処理実行中です。しばらくお待ちください。\")\n",
    "\n",
    "# テストデータの異常度\n",
    "anom_test = 1 - np.inner(mu, test_embeddings)\n",
    "\n",
    "# 閾値より異常度が大きければ異常標本と判定\n",
    "predict = (anom_test > ath).astype(np.int)\n",
    "\n",
    "# 正解データ\n",
    "answer = test_arr[:, 0].astype(np.float)\n",
    "\n",
    "\n",
    "# 精度計算\n",
    "acc = accuracy_score(answer, predict)\n",
    "print(\"Accuracy: {:.3f}\".format(acc))\n",
    "precision = precision_score(answer, predict)\n",
    "recall = recall_score(answer, predict)\n",
    "f1 = f1_score(answer, predict)\n",
    "cm = confusion_matrix(answer, predict)\n",
    "\n",
    "# 混同行列\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[0,1])\n",
    "cmd.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# テストデータに対する異常値のヒストグラムを正常データと異常データに分けてプロット\n",
    "s_anom_test = anom_test[test_arr[:, 0]=='0.0']\n",
    "c_anom_test = anom_test[test_arr[:, 0]=='1.0']\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "plt.plot(x, chi2.pdf(x, mhat, loc=0, scale=shat), c='k')\n",
    "plt.xlabel(\"a\", fontsize=18)\n",
    "plt.hist(s_anom_test, bins=100, density=True, range=(0,1.1), color=(0,1,0,0.8))\n",
    "plt.hist(c_anom_test, bins=100, density=True, range=(0,1.1), color=(0,0,1,0.5))\n",
    "plt.plot([ath, ath], [0, 9], c='r')\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.xlim(0.3,1.1)\n",
    "plt.ylim(0,9)\n",
    "plt.grid()\n",
    "plt.savefig(\"./PDF_test.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"次の処理を実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f0605-7ab0-4704-bd89-b4d517fc3b16",
   "metadata": {},
   "source": [
    "## 5. 文字列を入力して異常か検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be2bf3-1fbd-4818-8472-f8f5f548fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "text = widgets.Text(\n",
    "    value='テスト太郎 aaaaa',\n",
    "    placeholder='please type',\n",
    "    description='ﾃｽﾄ文:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ea047-b77c-44bb-b79a-84d82612c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"入力された文字列は「\" + text.value + \"」は\")\n",
    "check_arr = [text.value]\n",
    "check_embeddings = get_embeddings(check_arr)\n",
    "\n",
    "# チェックデータの異常度\n",
    "anom_check = 1 - np.inner(mu, check_embeddings) + 0.20  # 0.20は補正値\n",
    "\n",
    "# 閾値より異常度が大きければ異常標本と判定\n",
    "if anom_check > ath:\n",
    "    print(\"異常なデータである可能性が高いです。\")\n",
    "else:\n",
    "    print(\"異常なデータではありません。\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"閾値: \" + str(ath) + \" 異常度: \" + str(anom_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430d472-5af2-4292-990c-0b9493d55c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

